{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685de57f25848aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T01:57:45.792122Z",
     "start_time": "2024-09-28T01:57:44.026265Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "from tqdm import tqdm \n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "save_dir = \"../Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20520f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and save raw data\n",
    "import os\n",
    "os.makedirs(save_dir, exist_ok = True) #if dir not made make it else nothing\n",
    "ds = load_dataset(\"jlbaker361/wikiart\")\n",
    "ds.save_to_disk(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cadc1c4c3658fdd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T01:57:52.174558Z",
     "start_time": "2024-09-28T01:57:46.512Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data from disk\n",
    "ds = load_from_disk(save_dir, keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49971ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "# train_ds = ds['train'].remove_columns(['text', 'name', 'gen_style'])\n",
    "train_ds = ds['train'].remove_columns(['image'])\n",
    "train_ds\n",
    "test_df = pd.DataFrame(ds['train'])\n",
    "print(sys.getsizeof(test_df), sys.getsizeof(test_df)*10**(-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b3f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64181f5fbf0160dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T01:57:53.339548Z",
     "start_time": "2024-09-28T01:57:53.334818Z"
    }
   },
   "outputs": [],
   "source": [
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfbabeeb4050d0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T01:58:46.158650Z",
     "start_time": "2024-09-28T01:57:54.314856Z"
    }
   },
   "outputs": [],
   "source": [
    "image_widths = []\n",
    "image_heights = []\n",
    "for img in tqdm(ds['train'], desc=\"Extracting dimensions\"):\n",
    "    if 'image' in img:\n",
    "        # Extract width and height directly from the PIL image object\n",
    "        width, height = img['image'].size\n",
    "        image_widths.append(width)\n",
    "        image_heights.append(height)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(image_widths, bins=30, color='blue', alpha=0.7)\n",
    "plt.title(\"Distribution of Image Widths\")\n",
    "plt.xlabel(\"Width (pixels)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(image_heights, bins=30, color='green', alpha=0.7)\n",
    "plt.title(\"Distribution of Image Heights\")\n",
    "plt.xlabel(\"Height (pixels)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125bc35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MIN image size={min(image_widths), min(image_heights)}\")\n",
    "print(f\"MAX image size={max(image_widths), max(image_heights)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e95534a61d3d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9d7bb9b8e06e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T01:27:43.010512Z",
     "start_time": "2024-09-28T01:26:54.679274Z"
    }
   },
   "outputs": [],
   "source": [
    "styles = [img['style'] for img in tqdm(ds['train'], desc=\"Extracting styles\") if 'style' in img]\n",
    "style_counts = Counter(styles)\n",
    "del styles\n",
    "print(\"Class distribution in 'style':\")\n",
    "# this ensure the figure is in sorted order\n",
    "keys = []\n",
    "values =  []\n",
    "for style, count in style_counts.most_common():\n",
    "    print(f\"{style}: {count}\")\n",
    "    keys.append(style)\n",
    "    values.append(count)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(keys, values, color='skyblue', alpha=0.7)\n",
    "plt.xticks(rotation=90) \n",
    "plt.title(\"Distribution of Painting Styles\")\n",
    "plt.xlabel(\"Style\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "del keys, values, style_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "878828cf6190709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 2 Dimensional PCA with different colors for classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68692f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T01:22:16.616503Z",
     "start_time": "2024-09-29T01:22:16.267363Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "HEIGHT = 64\n",
    "WIDTH = 64\n",
    "\n",
    "# img_arr = [np.array(x['image'].resize((WIDTH, HEIGHT))).reshape(-1) \n",
    "#            for x in tqdm(ds['train'], desc=\"Processing Images for PCA\") if 'image' in x]\n",
    "# converts image to 1d np array by flattening (including rgb channels)\n",
    "def convert_img(x):\n",
    "    import numpy as np\n",
    "    HEIGHT = 64\n",
    "    WIDTH = 64\n",
    "    x['img_pixels'] = np.array(x['image'].resize((WIDTH, HEIGHT))).reshape(-1)/255\n",
    "    return x\n",
    "\n",
    "# TODO use full train set\n",
    "train_ds = ds['train'].select(range(5000))\n",
    "# convert pil image to resized and normalized pixel values\n",
    "train_ds = train_ds.map(convert_img, num_proc=4)\n",
    "# remove examples that do not match the actual length\n",
    "# alternatively we can pad images that do not have all channels\n",
    "train_ds = train_ds.filter(lambda x: len(x['img_pixels'])==HEIGHT*WIDTH*3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb21ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_styles(train_ds: DatasetDict):\n",
    "    unique_style_set = set()\n",
    "    for x in tqdm(train_ds):\n",
    "        unique_style_set.add(x['style'])\n",
    "    return list(unique_style_set)\n",
    "\n",
    "unique_styles = get_unique_styles(train_ds)\n",
    "unique_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d552abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def style2num(style, style_list):\n",
    "    return style_list.index(style)\n",
    "\n",
    "def add_style(x, style_list):\n",
    "    x['style_num'] = style2num(x['style'], style_list)\n",
    "    return x\n",
    "\n",
    "train_ds = train_ds.map(lambda x: add_style(x, unique_styles), num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46de3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "reduced_img_ar = pca.fit_transform(train_ds['img_pixels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96401cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(reduced_img_ar[:,0], reduced_img_ar[:,1], c=train_ds['style_num'])\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Visualization of the Images after PCA. Color coded by Image Style')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4277daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3a. Alternative to PCA, Average pixel brightness of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "476de1bb6d1127b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness_values = []\n",
    "\n",
    "for img in ds['train']:\n",
    "    if 'image' in img:\n",
    "        grayscale_img = img['image'].convert('L')\n",
    "        np_img = np.array(grayscale_img)\n",
    "        brightness_values.append(np.mean(np_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775d1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(brightness_values, bins=30, color='gray', alpha=0.7)\n",
    "plt.axvline(sum(brightness_values)/len(brightness_values), color='red', linestyle='dashed', linewidth=1)\n",
    "plt.title(\"Distribution of Image Brightness\")\n",
    "plt.xlabel(\"Brightness (mean pixel value)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8dfe6673ff04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Color Distributions if u can fix would be dope, super tired rn. need to batch somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dca164e482f53ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_rgb_distribution(dataset: DatasetDict, batch_size=32, num_batches=3):\n",
    "    train_dataset = dataset['train']\n",
    "    \n",
    "    for batch in range(num_batches):\n",
    "        start_idx = batch * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_samples = train_dataset.select(range(start_idx, end_idx))\n",
    "        # batch size x [img, R, G, B]\n",
    "        fig, axes = plt.subplots(batch_size, 4, figsize=(20, 5*batch_size))\n",
    "        fig.suptitle(f'RGB Distribution - Batch {batch+1}', fontsize=16)\n",
    "        \n",
    "        for i, sample in enumerate(batch_samples):\n",
    "            img = sample['image']\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            axes[i, 0].imshow(img)\n",
    "            axes[i, 0].set_title(f'Image {start_idx+i+1}')\n",
    "            axes[i, 0].axis('off')\n",
    "            for j, color in enumerate(['Red', 'Green', 'Blue']):\n",
    "                channel_data = img_array[:,:,j].ravel()\n",
    "                axes[i, j+1].hist(channel_data, bins=256, range=(0,255), color=color.lower(), alpha=0.7)\n",
    "                axes[i, j+1].set_title(f'{color} Channel')\n",
    "                axes[i, j+1].set_xlim(0, 255)\n",
    "                axes[i, j+1].set_ylim(0, img_array.shape[0]*img_array.shape[1]//10)  # Limit y-axis for better visibility\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69390e7cd591cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T01:52:11.864931Z",
     "start_time": "2024-09-28T01:51:44.968440Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "# if we want to iterate over the whole dataset\n",
    "num_batches=math.floor(len(ds['train'])/batch_size)\n",
    "visualize_rgb_distribution(ds, batch_size=batch_size, num_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f33d3cf657c29206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 1/147:   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m tqdm(batch, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mbatch_size\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_images\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mbatch_size\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m img:\n\u001b[1;32m---> 16\u001b[0m         grayscale_img \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[0;32m     17\u001b[0m         np_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(grayscale_img)\u001b[38;5;241m.\u001b[39mflatten()  \u001b[38;5;66;03m# Flatten the image array\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         pixel_values\u001b[38;5;241m.\u001b[39mextend(np_img)  \u001b[38;5;66;03m# Add to the main list of pixel values\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "pixel_values = []\n",
    "# Batching somewhere idk how \n",
    "for img in tqdm(ds['train'], desc=\"Extracting pixel values\"):\n",
    "    if 'image' in img:\n",
    "        grayscale_img = img['image'].convert('L')\n",
    "        np_img = np.array(grayscale_img).flatten()\n",
    "        pixel_values.extend(np_img)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(pixel_values, bins=256, color='black', alpha=0.7)\n",
    "plt.title(\"Distribution of Pixel Intensities\")\n",
    "plt.xlabel(\"Pixel Intensity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa158d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7aac10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch 1/147:   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m tqdm(batch, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mbatch_size\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_images\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39mbatch_size\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m img:\n\u001b[1;32m---> 17\u001b[0m         grayscale_img \u001b[38;5;241m=\u001b[39m img[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         np_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(grayscale_img)\u001b[38;5;241m.\u001b[39mflatten()  \u001b[38;5;66;03m# Flatten the image array\u001b[39;00m\n\u001b[0;32m     19\u001b[0m         pixel_values\u001b[38;5;241m.\u001b[39mupdate(np_img)  \u001b[38;5;66;03m# Update pixel values counter with the batch data\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a83b3432b54600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Small sample of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e531c96845dda0ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T01:59:50.613165Z",
     "start_time": "2024-09-28T01:59:50.609581Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_first_images(dataset: DatasetDict, num_images=5):\n",
    "    samples = dataset['train'].select(range(num_images))\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, img_data in enumerate(samples):\n",
    "        img = img_data['image']\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(img_data.get('style'))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd69080fcd79d523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T01:59:52.002322Z",
     "start_time": "2024-09-28T01:59:51.660741Z"
    }
   },
   "outputs": [],
   "source": [
    "display_first_images(ds, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1540b062f2dd414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
