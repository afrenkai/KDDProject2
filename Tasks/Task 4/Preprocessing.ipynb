{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T01:21:51.889830Z",
     "start_time": "2024-09-29T01:21:48.684364Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6b9615ffef7cb65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T01:21:56.508472Z",
     "start_time": "2024-09-29T01:21:53.020648Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(\"jlbaker361/wikiart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dfbeefe19b6bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "HEIGHT = 64\n",
    "WIDTH = 64\n",
    "CHANNELS = 3 # Should not matter \n",
    "BATCH_SIZE = 32\n",
    "CONVERT_TO_BW = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32d89527e211835",
   "metadata": {},
   "source": [
    "# Image Size Normalization, Augumentation, Convert to B&W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "328b9a999bc6521f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T01:24:49.663824Z",
     "start_time": "2024-09-29T01:24:18.356981Z"
    }
   },
   "outputs": [],
   "source": [
    "n_obs = 10\n",
    "train_ds = ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e94b8a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding\n",
    "# get unique class names\n",
    "\n",
    "def get_unique_styles(train_ds: DatasetDict):\n",
    "    return train_ds.unique('style')\n",
    "\n",
    "def style2idx(style, style_list):\n",
    "    return style_list.index(style)\n",
    "\n",
    "# get unique styles in the dataset\n",
    "# need to use full train dataset here\n",
    "unique_styles = get_unique_styles(train_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b189c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for cnn (needs to be one-hot encoded)\n",
    "# def encode_labels_cnn(x, unique_labels):\n",
    "#     x['label'] = np.zeros(len(unique_labels), dtype=np.int32)\n",
    "#     x['label'][style2idx(x['style'], unique_labels)] = 1\n",
    "#     return x\n",
    "\n",
    "# # for other clfs \n",
    "# def encode_labels(x, label_encoder: LabelEncoder):\n",
    "#     x['label'] = label_encoder.transform(x['style'])\n",
    "#     return x\n",
    "# label_encoder = LabelEncoder().fit(unique_styles)\n",
    "\n",
    "# train_ds = train_ds.map(lambda x: encode_labels(x, label_encoder), num_proc=4, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3c2e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_ds = train_ds.remove_columns(['text', 'name', 'gen_style'])\n",
    "# SAVE_DIR = '../processed_data'\n",
    "# processed_ds.save_to_disk(SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6639a03800bce78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T01:32:37.081356Z",
     "start_time": "2024-09-29T01:31:08.533434Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment_with_tf(image, shape):\n",
    "    # resize image\n",
    "    image = image.resize((HEIGHT,WIDTH))\n",
    "    # convert rgb image to grey scale\n",
    "    if CONVERT_TO_BW:\n",
    "        image = image.convert('L') # better support for converting compared to tf.Image.rbg_to_grayscale\n",
    "    # TODO: decide the following after subset, if subset add flipped images into dataset\n",
    "    # image = tf.image.random_flip_left_right(image)\n",
    "    # image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "    # image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    # image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    # reshape img array to the desired shape\n",
    "    image = tf.reshape(image, shape)\n",
    "    image = np.array(image, dtype=np.float64)\n",
    "    image = image * (1./255)\n",
    "\n",
    "    return image\n",
    "\n",
    "# augment over batches\n",
    "def augment(examples, shape):\n",
    "    examples['img_pixels'] = [augment_with_tf(img,shape) for img in examples['image']]\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4687ba6829866fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should work differently for cnn vs other models\n",
    "# other models would directly use the encoded labels (i.e \"string\" -> num)\n",
    "# cnn needs (0,1,0,0) i.e. one hot encoded output for this\n",
    "def to_tf_dataset(ds, shape, output_shape, batch_size=BATCH_SIZE):\n",
    "    def generator():\n",
    "        for row in ds:\n",
    "            yield row['img_pixels'], row['label'] \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator, \n",
    "        output_signature=(\n",
    "            # tf.TensorSpec(shape=(HEIGHT, WIDTH, CHANNELS), dtype=tf.float32),  # Image shape\n",
    "            tf.TensorSpec(shape=(shape), dtype=tf.float64),  # Image shape\n",
    "            tf.TensorSpec(shape=(output_shape), dtype=tf.int64)  # Label shape, (nclass,) for cnn; () for others\n",
    "        )\n",
    "    )\n",
    "    dataset = dataset.shuffle(buffer_size=1000).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6da37b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used in batches\n",
    "def encode_labels(x, label_encoder: LabelEncoder, for_CNN):\n",
    "    x['label'] = label_encoder.transform(np.array(x['style']).reshape(-1,1))\n",
    "    if for_CNN:\n",
    "        x['label']  = x['label'].toarray()\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f362be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels first (encoders have different input reqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8d8a9648e7a1c7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 73304/73304 [01:27<00:00, 835.94 examples/s] \n"
     ]
    }
   ],
   "source": [
    "for_CNN = True # prepare dataset for CNN (i.e shape (64,64,3) or (64,64)) and one-hot encoded labels\n",
    "unique_styles = np.array(unique_styles)\n",
    "\n",
    "if for_CNN:\n",
    "    encoder = OneHotEncoder().fit(unique_styles.reshape(-1,1))\n",
    "    shape = (HEIGHT, WIDTH, CHANNELS)\n",
    "    output_shape = (len(unique_styles))\n",
    "    if CONVERT_TO_BW:\n",
    "        shape = (HEIGHT, WIDTH)\n",
    "else:\n",
    "    encoder = LabelEncoder().fit(unique_styles)\n",
    "    shape = (HEIGHT*WIDTH*CHANNELS)\n",
    "    output_shape = ()\n",
    "    if CONVERT_TO_BW:\n",
    "        shape = (HEIGHT*WIDTH)\n",
    "\n",
    "\n",
    "train_ds_encoded = train_ds.map(lambda x: encode_labels(x, encoder, for_CNN), batched=True, num_proc=4)\n",
    "train_ds_augmented = train_ds_encoded.map(lambda x: augment(x, shape), batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc78cb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (11/11 shards): 100%|██████████| 73304/73304 [00:06<00:00, 10604.09 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# save dataset\n",
    "path = '../processed_data/'\n",
    "if for_CNN:\n",
    "    path += 'cnn' # input_shape = (HEIGHT, WIDTH), out_shape = (n_classes)\n",
    "else: \n",
    "    path += 'regular' # shape = (HEIGHT*WIDTH), out_shape = ()\n",
    "train_ds_augmented.save_to_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb09e44",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds_augmented' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_ds_augmented\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds_augmented' is not defined"
     ]
    }
   ],
   "source": [
    "train_ds_augmented[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c0399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to train models...\n",
    "train_final = to_tf_dataset(train_ds_augmented, shape, output_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
